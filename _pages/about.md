---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am broadly interested in *efficient computer vision and machine learning*, with a primary goal of reducing the enormous training costs associated with deep neural networks. More specifically, my research is dedicated to designing highly efficient algorithms that enable machine learning models to achieve near-optimal performance using only a small amount of data. Currently, I focus on *dataset distillation and coreset selection*, exploring both matching-based methods, generative model-based approaches and optimization-free methods. I am also interested in exploring its potential applicability beyond the image classification, particularly in addressing more complex computer vision tasks, such as image restoration, detection, and so on.


# ğŸ”¥ News
- *2025.10*: &nbsp;ğŸ‰ğŸ‰ 1 paper is accepted in IEEE TIP. 
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ 1 paper is accepted in Neural Networks. 
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ J'ai rÃ©ussi le DALF C1 de justesse, merci Ã  tous les professeurs de franÃ§ais.
- *2024.07*: &nbsp;ğŸ‰ğŸ‰ J'ai rÃ©ussi le DELF B2, merci Ã  tous les professeurs de franÃ§ais.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TIP 2025</div><img src='images/TIP2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unleashing the power of each distilled image](https://ieeexplore.ieee.org/document/11220248)

**Jingxuan Zhang**, Zhihua Chen*, and Lei Dai*

**IEEE TIP 2025** \| [**Code**](https://github.com/Zhang-Jing-Xuan/DD-UP) <strong><span class='show_paper_citations' data='1rRBJtQAAAAJ:Tyk-4Ss8FVUC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neural Networks 2025</div><img src='images/NN2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Gradient amplification for gradient matching based dataset distillation](https://www.sciencedirect.com/science/article/abs/pii/S0893608025006999)

**Jingxuan Zhang**, Zhihua Chen*, Lei Dai, Ping Li, and Bin Sheng*

**Neural Networks 2025** \| [**Code**](https://github.com/Zhang-Jing-Xuan/DD-GA) <strong><span class='show_paper_citations' data='1rRBJtQAAAAJ:Tyk-4Ss8FVUC'></span></strong>
</div>
</div>

- [Unleashing the power of each distilled image](https://github.com/Zhang-Jing-Xuan/DD-UP), **Jingxuan Zhang**, Zhihua Chen*, and Lei Dai*, **IEEE TIP 2025**.
- [Gradient amplification for gradient matching based dataset distillation](https://github.com/Zhang-Jing-Xuan/DD-GA), **Jingxuan Zhang**, Zhihua Chen*, Lei Dai, Ping Li, and Bin Sheng*, **Neural Networks 2025**.

# ğŸ– Honors and Awards
- *2022 & 2023* First Prize of Master Academic Scholarship.
- *2022* First Prize of Master Academic Scholarship. 
- *2020* Bronze Medal of ICPC Asia Regional Contest, Shanghai Site. 
- *2019 & 2020* Second Prize of C/C++ Programming (Group A) of Lanqiao Cup, Shanghai.
- *2019 & 2020* First-class Outstanding Innovative Talent Scholarship of ECUST.
- *2019 & 2020* First-class Scholarship of ECUST.
- *2019* Second Prize of National Undergraduate Mathematics Competition (Non-Mathematics Major).
- *2019* First Prize of ECUST Mathematics Grand Competition.

# ğŸ“– Educations
- *2022.09 - Present*, East China University of Science and Technology, Shanghai, China, Ph.D. in Computer Science and Technology. 
- *2018.09 - 2022.06*, East China University of Science and Technology, Shanghai, China, B.E. in Computer Science and Technology.
